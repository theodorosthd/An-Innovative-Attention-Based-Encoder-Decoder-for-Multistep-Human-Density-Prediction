{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Gym_Prediction_Models.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNS+pabEecCXa347qpM7eKL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"BGbQ8nrzn6ng"},"source":["! pip install pmdarima"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UegDQzvBlM6z"},"source":["import pandas as pd\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQNLs0ValtSV","executionInfo":{"status":"ok","timestamp":1630252639224,"user_tz":-180,"elapsed":5,"user":{"displayName":"Angelos-Christos Maroudis","photoUrl":"","userId":"17610104408260752759"}},"outputId":"c7d3769b-14da-4e93-9a4f-2133ea21af9b"},"source":["df = pd.read_csv('gdrive/MyDrive/Gym Dataset/gym_dataset.csv' )\n","df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(62184, 11)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":371},"id":"VOCEhYB-mIti","executionInfo":{"status":"ok","timestamp":1630252640009,"user_tz":-180,"elapsed":3,"user":{"displayName":"Angelos-Christos Maroudis","photoUrl":"","userId":"17610104408260752759"}},"outputId":"6b0edf0c-ce6d-4a3c-a1a2-0b7be61bde33"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>number_people</th>\n","      <th>date</th>\n","      <th>timestamp</th>\n","      <th>day_of_week</th>\n","      <th>is_weekend</th>\n","      <th>is_holiday</th>\n","      <th>temperature</th>\n","      <th>is_start_of_semester</th>\n","      <th>is_during_semester</th>\n","      <th>month</th>\n","      <th>hour</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37</td>\n","      <td>2015-08-14 17:00:11-07:00</td>\n","      <td>61211</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>71.76</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>45</td>\n","      <td>2015-08-14 17:20:14-07:00</td>\n","      <td>62414</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>71.76</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>40</td>\n","      <td>2015-08-14 17:30:15-07:00</td>\n","      <td>63015</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>71.76</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>44</td>\n","      <td>2015-08-14 17:40:16-07:00</td>\n","      <td>63616</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>71.76</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>45</td>\n","      <td>2015-08-14 17:50:17-07:00</td>\n","      <td>64217</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>71.76</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>17</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   number_people                       date  ...  month  hour\n","0             37  2015-08-14 17:00:11-07:00  ...      8    17\n","1             45  2015-08-14 17:20:14-07:00  ...      8    17\n","2             40  2015-08-14 17:30:15-07:00  ...      8    17\n","3             44  2015-08-14 17:40:16-07:00  ...      8    17\n","4             45  2015-08-14 17:50:17-07:00  ...      8    17\n","\n","[5 rows x 11 columns]"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"FMNrlgKenFdk"},"source":["### ARMA/ARIMA Multi Step univariate "]},{"cell_type":"code","metadata":{"id":"FOoiFIDjn5vq"},"source":["# return a list of relative forecast lead times\n","def get_lead_times():\n","\treturn [1, 2, 3, 4, 5, 6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T1DsmgyyotGJ"},"source":["predictionSteps.clear()\n","testSteps.clear()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJhpXcIboXhK"},"source":["predictionSteps = []\n","for i in range(6):\n","  predictionSteps.append([])\n","\n","offset = 6\n","testSteps = []\n","for i in range(6):\n","  testSteps.append([])\n","\n","X = df.number_people.values\n","size = 52_560\n","for i in range(6):\n","  testSteps[i] = X[size+i:int(len(X)-offset+i)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN0nrmuemt-i"},"source":["from numpy import array\n","from numpy import nanmedian\n","from statsmodels.tsa.arima.model import ARIMA\n","import time\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from math import sqrt\n","from matplotlib import pyplot\n","from warnings import catch_warnings\n","from warnings import filterwarnings\n","\n","X = df.number_people.values\n","size = 52_560\n","train, test = X[0:size], X[size:int(len(X)-offset)]\n","history = [x for x in train]\n","predictions = list()\n","total_size = len(test)\n","count = 1\n","for t in range(int(len(test))):\n","  print('current=%d, total=%d' % (count, total_size))\n","  count = count + 1\n","  # define the model\n","  model = ARIMA(history, order=(0,1,0))\n","  # return a nan forecast in case of exception\n","  try:\n","    # ignore statsmodels warnings\n","    with catch_warnings():\n","      filterwarnings(\"ignore\")\n","      # fit the model\n","      model_fit = model.fit()\n","      # forecast half an hour\n","      yhat = model_fit.predict(len(history), len(history)+6)\n","      # extract lead times\n","      lead_times = array(get_lead_times())\n","      indices = lead_times - 1\n","      print(yhat[indices])\n","      for i in range(6):\n","        predictionSteps[i].append(yhat[i])\n","        #predictions.append(yhat[i])\n","      obs = test[t]\n","      #for i in range(6):\n","        #history.append(obs[i])\n","      history.append(obs)\n","      #print('predicted=%f, expected=%f' % (yhat, obs))\n","  except:\n","    print(\"exception\")\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nNEl57WPn1eu"},"source":["## Calculating Metrics \n","\n","scores = list()\n","scores2 = list()\n","# evaluate forecasts\n","for i in range(6):\n","  mae = mean_absolute_error(testSteps[i], predictionSteps[i])\n","  #print('MAE: %.3f' % mae)\n","  scores.append(mae)\n","  rmse = sqrt(mean_squared_error(testSteps[i], predictionSteps[i]))\n","  #print('RMSE: %.3f' % rmse)\n","  scores2.append(rmse)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JvLZ_-8viLgF","executionInfo":{"status":"ok","timestamp":1630259643825,"user_tz":-180,"elapsed":274,"user":{"displayName":"Angelos-Christos Maroudis","photoUrl":"","userId":"17610104408260752759"}},"outputId":"577b2810-5dcc-40d8-ccb2-7dc931bc35a8"},"source":["## Printing Metrics \n","\n","s_scores = ', '.join(['%.4f' % s for s in scores])\n","s_scores2 = ', '.join(['%.4f' % s for s in scores2])\n","print('%s:  %s' % (\"MAE\",  s_scores))\n","print('%s:  %s' % (\"RMSE\", s_scores2))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MAE:  2.8640, 3.4530, 3.8846, 4.2698, 4.6234, 4.9557\n","RMSE:  4.6339, 5.4395, 6.0139, 6.5867, 7.0748, 7.6008\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P6_Cr2TWD1Ro"},"source":["#### ARIMA MODEL evaluation metrics \n","* MAE: 2.8640, 3.4530, 3.8846, 4.2698, 4.6234, 4.9557\n","* RMSE: 4.6339, 5.4395, 6.0139, 6.5867, 7.0748, 7.6008"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQvjt6uWD09Q","executionInfo":{"status":"ok","timestamp":1630260158065,"user_tz":-180,"elapsed":259,"user":{"displayName":"Angelos-Christos Maroudis","photoUrl":"","userId":"17610104408260752759"}},"outputId":"2d325155-cc3b-4184-f78c-0f82accb3fe0"},"source":["#Overall Metrics \n","\n","# Add Each steps metric into mae_overall and rmse overall \n","mae_overall = (2.8640 + 3.4530 + 3.8846 + 4.2698 + 4.6234 + 4.9557)/6\n","rmse_overall = (4.6339 + 5.4395 + 6.0139 + 6.5867 + 7.0748 + 7.6008)/6\n","#mae_overall, rmse_overall\n","print('MAE Overall: %.3f' % mae_overall)\n","print('RMSE Overall: %.3f' % rmse_overall)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MAE Overall: 4.008\n","RMSE Overall: 6.225\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LayNfD09o8uK"},"source":["## ML linear regression model \n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5qpTwNapALW","executionInfo":{"status":"ok","timestamp":1630260568126,"user_tz":-180,"elapsed":172539,"user":{"displayName":"Angelos-Christos Maroudis","photoUrl":"","userId":"17610104408260752759"}},"outputId":"10f172fb-d113-4b67-c8c3-e859955f9bf7"},"source":["# recursive multi-step forecast with linear algorithms\n","from math import sqrt\n","from numpy import split\n","from numpy import array\n","from pandas import read_csv\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from matplotlib import pyplot\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import Lasso\n","from sklearn.linear_model import Ridge\n","from sklearn.linear_model import ElasticNet\n","from sklearn.linear_model import HuberRegressor\n","from sklearn.linear_model import Lars\n","from sklearn.linear_model import LassoLars\n","from sklearn.linear_model import PassiveAggressiveRegressor\n","from sklearn.linear_model import RANSACRegressor\n","from sklearn.linear_model import SGDRegressor\n"," \n","# split a univariate dataset into train/test sets\n","def split_dataset(data):\n","\t# split into standard weeks\n","\ttrain, test = data[:52_560], data[52_560:]\n","\t# restructure into windows of weekly data\n","\ttrain = array(split(train, int(len(train)/6)))\n","\ttest = array(split(test, len(test)/6))\n","\treturn train, test\n","\n"," \n","# evaluate one or more weekly forecasts against expected values\n","def evaluate_forecasts(actual, predicted):\n","\tscores = list()\n","\tscores2 = list()\n","\t# calculate an RMSE score for each day\n","\tfor i in range(actual.shape[1]):\n","\t\t# calculate mse\n","\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n","\t\t# calculate rmse\n","\t\trmse = sqrt(mse)\n","    #calculate mae\n","\n","\t\tmae = mean_absolute_error(actual[:, i], predicted[:, i])\n","\t\t# store\n","\t\tscores.append(rmse)\n","\t\tscores2.append(mae)\n","\t# calculate overall RMSE\n","\ts = 0\n","\tfor row in range(actual.shape[0]):\n","\t\tfor col in range(actual.shape[1]):\n","\t\t\ts += (actual[row, col] - predicted[row, col])**2\n","\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n","\treturn score, scores, scores2\n"," \n","# summarize scores\n","def summarize_scores(name, score, scores, scores2):\n","\ts_scores = ', '.join(['%.4f' % s for s in scores])\n","\ts_scores2 = ', '.join(['%.4f' % s for s in scores2])\n","\tprint('%s: [%.3f] %s' % (name, score, s_scores))\n","\tprint('%s: %s' % (name, s_scores2))\n"," \n","# prepare a list of ml models\n","def get_models(models=dict()):\n","\t# linear models\n","\tmodels['lr'] = LinearRegression()\n","\tprint('Defined %d Recursive models' % len(models))\n","\treturn models\n"," \n","# create a feature preparation pipeline for a model\n","def make_pipeline(model):\n","\tsteps = list()\n","\t# standardization\n","\tsteps.append(('standardize', StandardScaler()))\n","\t# normalization\n","\tsteps.append(('normalize', MinMaxScaler()))\n","\t# the model\n","\tsteps.append(('model', model))\n","\t# create pipeline\n","\tpipeline = Pipeline(steps=steps)\n","\treturn pipeline\n"," \n","# make a recursive multi-step forecast\n","def forecast(model, input_x, n_input):\n","\tyhat_sequence = list()\n","\tinput_data = [x for x in input_x]\n","\tfor j in range(6):\n","\t\t# prepare the input data\n","\t\tX = array(input_data[-n_input:]).reshape(1, n_input)\n","\t\t# make a one-step forecast\n","\t\tyhat = model.predict(X)[0]\n","\t\t# add to the result\n","\t\tyhat_sequence.append(yhat)\n","\t\t# add the prediction to the input\n","\t\tinput_data.append(yhat)\n","\treturn yhat_sequence\n"," \n","# convert windows of weekly multivariate data into a series of total power\n","def to_series(data):\n","\t# extract just the total power from each week\n","\tseries = [week[:, 0] for week in data]\n","\t# flatten into a single series\n","\tseries = array(series).flatten()\n","\treturn series\n"," \n","# convert history into inputs and outputs\n","def to_supervised(history, n_input):\n","\t# convert history to a univariate series\n","\tdata = to_series(history)\n","\tX, y = list(), list()\n","\tix_start = 0\n","\t# step over the entire history one time step at a time\n","\tfor i in range(len(data)):\n","\t\t# define the end of the input sequence\n","\t\tix_end = ix_start + n_input\n","\t\t# ensure we have enough data for this instance\n","\t\tif ix_end < len(data):\n","\t\t\tX.append(data[ix_start:ix_end])\n","\t\t\ty.append(data[ix_end])\n","\t\t# move along one time step\n","\t\tix_start += 1\n","\treturn array(X), array(y)\n"," \n","# fit a model and make a forecast\n","def sklearn_predict(model, history, n_input):\n","\t# prepare data\n","\ttrain_x, train_y = to_supervised(history, n_input)\n","\t# make pipeline\n","\tpipeline = make_pipeline(model)\n","\t# fit the model\n","\tpipeline.fit(train_x, train_y)\n","\t# predict the week, recursively\n","\tyhat_sequence = forecast(pipeline, train_x[-1, :], n_input)\n","\treturn yhat_sequence\n"," \n","# evaluate a single model\n","def evaluate_model(model, train, test, n_input):\n","\t# history is a list of hourly data\n","\thistory = [x for x in train]\n","\t# walk-forward validation over each hour\n","\tpredictions = list()\n","\tfor i in range(len(test)):\n","\t\t# predict the hour\n","\t\tyhat_sequence = sklearn_predict(model, history, n_input)\n","\t\t# store the predictions\n","\t\tpredictions.append(yhat_sequence)\n","\t\t# get real observation and add to history for predicting the next hour\n","\t\thistory.append(test[i, :])\n","\tpredictions = array(predictions)\n","\t# evaluate predictions days for each hour\n","\tscore, scores, scores2 = evaluate_forecasts(test[:, :, 0], predictions)\n","\treturn score, scores, scores2\n"," \n","df2 = df[['number_people']]\n","train, test = split_dataset(df2.values)\n","# prepare the models to evaluate\n","models = get_models()\n","n_input = 3 #prior timestamp observations\n","# evaluate each model\n","\n","for name, model in models.items():\n","\t# evaluate and get scores\n","\tscore, scores, scores2 = evaluate_model(model, train, test, n_input)\n","\t# summarize scores\n","\tsummarize_scores(name, score, scores, scores2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Defined 1 Recursive models\n","lr: [6.647] 5.0811, 5.7673, 6.2328, 6.9546, 7.3028, 8.0914\n","lr: 3.4553, 4.1442, 4.5002, 5.0973, 5.5788, 6.1500\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VCM3ZlTOGui0"},"source":["### Linear Regression Model evaluation metrics\n","\n","* MAE: 3.4553, 4.1442, 4.5002, 5.0973, 5.5788, 6.1500\n","* RMSE: 5.0811, 5.7673, 6.2328, 6.9546, 7.3028, 8.0914\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AxG-t3eCFxSJ","executionInfo":{"status":"ok","timestamp":1630260766579,"user_tz":-180,"elapsed":297,"user":{"displayName":"Angelos-Christos Maroudis","photoUrl":"","userId":"17610104408260752759"}},"outputId":"e9686e5e-9223-4a55-c5aa-270152175326"},"source":["#Overall Metrics \n","\n","mae_overall = (3.4553 + 4.1442 + 4.5002 + 5.0973 + 5.5788 + 6.1500)/6\n","rmse_overall = 6.647\n","#mae_overall, rmse_overall\n","print('MAE Overall: %.3f' % mae_overall)\n","print('RMSE Overall: %.3f' % rmse_overall)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MAE Overall: 4.821\n","RMSE Overall: 6.647\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"w523u901Hr9J"},"source":["# ML Non Linear Model\n","\n"]},{"cell_type":"code","metadata":{"id":"rLHVnk29HSSs"},"source":["# spot check nonlinear algorithms\n","from numpy import load\n","from numpy import loadtxt\n","from numpy import nan\n","from numpy import isnan\n","from numpy import count_nonzero\n","from numpy import unique\n","from numpy import array\n","from sklearn.base import clone\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.tree import ExtraTreeRegressor\n","from sklearn.svm import SVR\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.ensemble import BaggingRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.ensemble import ExtraTreesRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_YyUkyOfH-Ql","executionInfo":{"status":"ok","timestamp":1630269082766,"user_tz":-180,"elapsed":8021504,"user":{"displayName":"Angelos-Christos Maroudis","photoUrl":"","userId":"17610104408260752759"}},"outputId":"102ba742-f618-420e-c347-dc081668b584"},"source":["from math import sqrt\n","from numpy import split\n","from numpy import array\n","from pandas import read_csv\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from matplotlib import pyplot\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import Lasso\n","from sklearn.linear_model import Ridge\n","from sklearn.linear_model import ElasticNet\n","from sklearn.linear_model import HuberRegressor\n","from sklearn.linear_model import Lars\n","from sklearn.linear_model import LassoLars\n","from sklearn.linear_model import PassiveAggressiveRegressor\n","from sklearn.linear_model import RANSACRegressor\n","from sklearn.linear_model import SGDRegressor\n","   \n","# split a univariate dataset into train/test sets\n","def split_dataset(data):\n","\t# split into standard weeks\n","\ttrain, test = data[:52_560], data[52_560:]\n","\t# restructure into windows of weekly data\n","\ttrain = array(split(train, int(len(train)/6)))\n","\ttest = array(split(test, len(test)/6))\n","\treturn train, test\n"," \n","# evaluate one or more weekly forecasts against expected values\n","def evaluate_forecasts(actual, predicted):\n","\tscores = list()\n","\tscores2 = list()\n","\t# calculate an RMSE score for each day\n","\tfor i in range(actual.shape[1]):\n","\t\t# calculate mse\n","\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n","\t\t# calculate rmse\n","\t\trmse = sqrt(mse)\n","    #calculate mae\n","\n","\t\tmae = mean_absolute_error(actual[:, i], predicted[:, i])\n","\t\t# store\n","\t\tscores.append(rmse)\n","\t\tscores2.append(mae)\n","\t# calculate overall RMSE\n","\ts = 0\n","\tfor row in range(actual.shape[0]):\n","\t\tfor col in range(actual.shape[1]):\n","\t\t\ts += (actual[row, col] - predicted[row, col])**2\n","\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n","\treturn score, scores, scores2\n"," \n","# summarize scores\n","def summarize_scores(name, score, scores, scores2):\n","\ts_scores = ', '.join(['%.4f' % s for s in scores])\n","\ts_scores2 = ', '.join(['%.4f' % s for s in scores2])\n","\tprint('%s: [%.3f] %s' % (name, score, s_scores))\n","\tprint('%s: %s' % (name, s_scores2))\n"," \n","# prepare a list of ml models\n","def get_models(models=dict()):\n","\t# non-linear models\n","\tmodels['knn'] = KNeighborsRegressor(n_neighbors=7)\n","\t# # ensemble models\n","\tn_trees = 100\n","\tmodels['gbm'] = GradientBoostingRegressor(n_estimators=n_trees)\n","\tprint('Defined %d models' % len(models))\n","\treturn models\n"," \n","# create a feature preparation pipeline for a model\n","def make_pipeline(model):\n","\tsteps = list()\n","\t# standardization\n","\tsteps.append(('standardize', StandardScaler()))\n","\t# normalization\n","\tsteps.append(('normalize', MinMaxScaler()))\n","\t# the model\n","\tsteps.append(('model', model))\n","\t# create pipeline\n","\tpipeline = Pipeline(steps=steps)\n","\treturn pipeline\n"," \n","# convert history into inputs and outputs\n","def to_supervised(history, output_ix):\n","\tX, y = list(), list()\n","\t# step over the entire history one time step at a time\n","\tfor i in range(len(history)-1):\n","\t\tX.append(history[i][:,0])\n","\t\ty.append(history[i + 1][output_ix,0])\n","\treturn array(X), array(y)\n"," \n","# fit a model and make a forecast\n","def sklearn_predict(model, history):\n","\tyhat_sequence = list()\n","\t# fit a model for each forecast day\n","\tfor i in range(6):\n","\t\t# prepare data\n","\t\ttrain_x, train_y = to_supervised(history, i)\n","\t\t# make pipeline\n","\t\tpipeline = make_pipeline(model)\n","\t\t# fit the model\n","\t\tpipeline.fit(train_x, train_y)\n","\t\t# forecast\n","\t\tx_input = array(train_x[-1, :]).reshape(1,6)\n","\t\tyhat = pipeline.predict(x_input)[0]\n","\t\t# store\n","\t\tyhat_sequence.append(yhat)\n","\treturn yhat_sequence\n"," \n","# evaluate a single model\n","def evaluate_model(model, train, test):\n","\t# history is a list of weekly data\n","\thistory = [x for x in train]\n","\t# walk-forward validation over each week\n","\tpredictions = list()\n","\tfor i in range(len(test)):\n","\t\t# predict the week\n","\t\tyhat_sequence = sklearn_predict(model, history)\n","\t\t# store the predictions\n","\t\tpredictions.append(yhat_sequence)\n","\t\t# get real observation and add to history for predicting the next week\n","\t\thistory.append(test[i, :])\n","\tpredictions = array(predictions)\n","\t# evaluate predictions days for each week\n","\tscore, scores, scores2 = evaluate_forecasts(test[:, :, 0], predictions)\n","\treturn score, scores, scores2\n"," \n","\n","df2 = df[['number_people']]\n","# split into train and test\n","train, test = split_dataset(df2.values)\n","# prepare the models to evaluate\n","models = get_models()\n","# evaluate each model\n","\n","for name, model in models.items():\n","\t# evaluate and get scores\n","\tscore, scores, scores2 = evaluate_model(model, train, test)\n","\t# summarize scores\n","\tsummarize_scores(name, score, scores, scores2)\n","\t# plot scores\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Defined 2 models\n","knn: [8.640] 7.8398, 8.3037, 8.4015, 8.9987, 8.9496, 9.2662\n","knn: 5.1589, 5.5033, 5.5837, 6.0092, 6.3286, 6.5630\n","gbm: [8.677] 7.8407, 8.2579, 8.4183, 8.9880, 9.0486, 9.4098\n","gbm: 5.1974, 5.5449, 5.6873, 6.0631, 6.4856, 6.7578\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uJZ-R_XbHzrk"},"source":["### Non Linear Regression Model evaluation metrics\n","\n","* KNN\n","  * MAE: 5.1589, 5.5033, 5.5837, 6.0092, 6.3286, 6.5630\n","  * RMSE: 7.8398, 8.3037, 8.4015, 8.9987, 8.9496, 9.2662"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4mAKgCR-H2Fo","executionInfo":{"status":"ok","timestamp":1630269083960,"user_tz":-180,"elapsed":4,"user":{"displayName":"Angelos-Christos Maroudis","photoUrl":"","userId":"17610104408260752759"}},"outputId":"fe367373-2dd1-44d9-9061-0d67043565fc"},"source":["#Overall Metrics \n","\n","mae_overall = (5.1589 + 5.5033 + 5.5837 + 6.0092 + 6.3286 + 6.5630)/6\n","rmse_overall = 8.640\n","#mae_overall, rmse_overall\n","print('MAE Overall: %.3f' % mae_overall)\n","print('RMSE Overall: %.3f' % rmse_overall)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MAE Overall: 5.858\n","RMSE Overall: 8.640\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"udjFQboBVl59"},"source":[""],"execution_count":null,"outputs":[]}]}